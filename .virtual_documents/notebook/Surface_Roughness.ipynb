





from IPython.display import Image
Image(filename='VWjzBJl.png')








import pandas as pd
import os
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import time
import joblib


from sklearn.preprocessing import PolynomialFeatures, StandardScaler
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.ensemble import RandomForestRegressor
from sklearn.neighbors import KNeighborsRegressor
from xgboost import XGBRegressor
from sklearn.pipeline import Pipeline
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, make_scorer, mean_absolute_percentage_error
import numpy as np
import warnings
from scipy.optimize import minimize





base_dir = r"C:\Users\santo\OneDrive\Documents\GitHub\Surface_Roughness"

file_paths = [f"{base_dir}/data/raw/Exp1.csv",
              f"{base_dir}/data/raw/Exp2.csv"]

# Load Data
df_list = []
for path in file_paths:
    if os.path.exists(path):
        try:
            df = pd.read_csv(path)
            print(f"Data loaded successfully from: {path}")
            print(f"dataset shape: {df.shape}")
            df_list.append(df)
        except Exception as e:
            print(f"Found '{path}' but failed to load")
            continue

# File was not Found
if df is None:
    print("Error: data files were found.")
    print("Place dataset in the appropriate directory.")

# Merge into a single DataFrame
if df_list:
    merged_df = pd.concat(df_list, ignore_index=True)
    print(f"\nMerged DataFrame shape: {merged_df.shape}")
else:
    print("No data loaded. Please check file formats or paths.")





print("\033[1m"+"\n--- First 5 rows of the dataset ---"+"\033[0m")
print(merged_df.head())
print("\n"*3)

print("\033[1m"+"\n--- Dataset Info  ---"+"\033[0m")
merged_df.info()
print("\n"*3)

print("\033[1m"+"\n--- Statistical Summary of Numerical Columns ---"+"\033[0m")
print(merged_df.describe().T) 
print("\n")


print("\033[1m"+"\n--- Missing Values  ---"+"\033[0m")
missing_values = merged_df.isnull().sum()
print(missing_values[missing_values > 0])
if missing_values.sum() == 0:
    print("No missing values found in the dataset.")
    print("\n")
    
print("\033[1m"+"\n--- Duplicate Rows Check ---"+"\033[0m")
num_duplicates = merged_df.duplicated().sum()
print(f"Number of duplicate rows: {num_duplicates}")
if num_duplicates > 0:
    print(f"Dropping {num_duplicates} duplicate rows...")
    print("\n")
    df.drop_duplicates(inplace=True)
    print(f"New dataset shape after dropping duplicates: {df.shape}")
    print("\n")
else:
    print("No duplicate rows found.")
    print("\n")







# Drop the specified columns
# To align with our project's goal of predicting `Surface_Roughness_Ra` solely from controllable machining parameters
columns_to_drop = [
    'Run_ID', 'Experiment', 'Replica', 'Tool_ID', 'Group', 'Subgroup', 'Position', 'Cond', 
    'Machined_length', 'Init_diameter', 'Final_diameter', 'CTime', 'R_measurement',
    'Rz', 'Rsk', 'Rku', 'RSm', 'Rt', 'Condition'
    
]

# Drop the specified columns
# Use errors='ignore' in case some columns were not present (e.g., if you run this multiple times)
merged_df.drop(columns=columns_to_drop, inplace=True, errors='ignore')


# Rename columns  
rename_mapping = {
    'ap': 'Depth_of_Cut_ap',       
    'vc': 'Cutting_Speed_vc',
    'f': 'Feed_Rate_f',
    'Ra': 'Surface_Roughness_Ra',    
    'TCond': 'Tool_Wear'

}

# Apply renaming only to columns that exist in the DataFrame
merged_df.rename(columns={k: v for k, v in rename_mapping.items() if k in merged_df.columns}, inplace=True)


merged_df.head()



# Plots display options 
pd.set_option('display.max_columns', None)  
pd.set_option('display.width', 1000)        

# plots style and color palette 
plt.style.use('fivethirtyeight')      
sns.set_palette('crest')                  


plt.figure(figsize=(10, 6))
sns.histplot(merged_df['Surface_Roughness_Ra'], kde=True, bins=40)
plt.title('Distribution of Surface Roughness (Ra)')
plt.xlabel('Surface Roughness Ra (µm)')
plt.ylabel('Frequency')
plt.grid(True, linestyle='--', alpha=0.7)
plt.show()






# --- Univariate Analysis: Count Plots for Discrete Parameters with Counts ---

fig, axes = plt.subplots(1, 3, figsize=(20, 6))

# Loop through each parameter to create its count plot and add counts
parameters = ['Depth_of_Cut_ap', 'Cutting_Speed_vc', 'Feed_Rate_f']
x_labels = ['Depth of Cut (mm)', 'Cutting Speed (m/min)', 'Feed Rate (mm/rev)']
titles = ['Distribution of Depth of Cut (ap)', 'Distribution of Cutting Speed (vc)', 'Distribution of Feed Rate (f)']

for i, param in enumerate(parameters):
    ax = axes[i]
    sns.countplot(x=param, data=merged_df, ax=ax, palette='crest',hue=param, legend=False)
    ax.set_title(titles[i])
    ax.set_xlabel(x_labels[i])
    ax.set_ylabel('Frequency')
    ax.grid(axis='y', linestyle='--', alpha=0.7) 

    # Add count labels on top of each bar
    for container in ax.containers: 
        for patch in container.patches:
            height = patch.get_height()
            ax.text(patch.get_x() + patch.get_width() / 2., 
                    height + 3, f'{int(height)}', 
                    ha='center', va='bottom') 

plt.tight_layout()
plt.show()


# --- Plots with Swarm Plots ---
fig, axes = plt.subplots(1, 3, figsize=(22, 6))

# Ra vs. Depth of Cut with Swarm Plot
sns.swarmplot(x='Depth_of_Cut_ap', y='Surface_Roughness_Ra', data=merged_df, ax=axes[0], hue='Depth_of_Cut_ap', palette='crest', s=5, legend=False)
axes[0].set_title('Surface Roughness (Ra) by Depth of Cut ')
axes[0].set_xlabel('Depth of Cut (mm)')
axes[0].set_ylabel('Surface Roughness Ra (µm)')
axes[0].grid(True, linestyle='--', alpha=0.7)

# Ra vs. Cutting Speed with Swarm Plot
sns.swarmplot(x='Cutting_Speed_vc', y='Surface_Roughness_Ra', data=merged_df, ax=axes[1], hue='Cutting_Speed_vc', palette='crest', s=5, legend=False)
axes[1].set_title('Surface Roughness (Ra) by Cutting Speed ')
axes[1].set_xlabel('Cutting Speed (m/min)')
axes[1].set_ylabel('Surface Roughness Ra (µm)')

# Ra vs. Feed Rate with Swarm Plot
sns.swarmplot(x='Feed_Rate_f', y='Surface_Roughness_Ra', data=merged_df, ax=axes[2],hue='Feed_Rate_f', palette='crest', s=5, legend=False)
axes[2].set_title('Surface Roughness (Ra) by Feed Rate ')
axes[2].set_xlabel('Feed Rate (mm/rev)')
axes[2].set_ylabel('Surface Roughness Ra (µm)')
axes[2].grid(True, linestyle='--', alpha=0.7)



plt.tight_layout()
plt.show()
warnings.filterwarnings("ignore", category=UserWarning)


fig, axes = plt.subplots(1, 3, figsize=(22, 6))

# Ra vs. Depth of Cut with Box Plot
sns.boxplot(x='Depth_of_Cut_ap', y='Surface_Roughness_Ra', data=merged_df, ax=axes[0], hue='Depth_of_Cut_ap', palette='crest', legend=False)
axes[0].set_title('Surface Roughness (Ra) by Depth of Cut (Box Plot)')
axes[0].set_xlabel('Depth of Cut (mm)')
axes[0].set_ylabel('Surface Roughness Ra (µm)')
axes[0].grid(True, linestyle='--', alpha=0.7)

# Ra vs. Cutting Speed with Box Plot
sns.boxplot(x='Cutting_Speed_vc', y='Surface_Roughness_Ra', data=merged_df, ax=axes[1], hue='Cutting_Speed_vc', palette='crest', legend=False)
axes[1].set_title('Surface Roughness (Ra) by Cutting Speed (Box Plot)')
axes[1].set_xlabel('Cutting Speed (m/min)')
axes[1].set_ylabel('Surface Roughness Ra (µm)')
axes[1].grid(True, linestyle='--', alpha=0.7)

# Ra vs. Feed Rate with Box Plot
sns.boxplot(x='Feed_Rate_f', y='Surface_Roughness_Ra', data=merged_df, ax=axes[2], hue='Feed_Rate_f', palette='crest', legend=False)
axes[2].set_title('Surface Roughness (Ra) by Feed Rate (Box Plot)')
axes[2].set_xlabel('Feed Rate (mm/rev)')
axes[2].set_ylabel('Surface Roughness Ra (µm)')
axes[2].grid(True, linestyle='--', alpha=0.7)

plt.tight_layout()
plt.show()





#Correlation Analysis


plt.figure(figsize=(10, 8))
correlation_matrix = merged_df.corr()
sns.heatmap(correlation_matrix, annot=True, cmap='Blues', fmt=".2f", linewidths=.5)
plt.title('Correlation Matrix of Machining Parameters and Roughness Parameters')
plt.show()








merged_df.to_csv(f'{base_dir}/data/processed/cleaned_data.csv', index=False)




















base_dir = r"C:\Users\santo\OneDrive\Documents\GitHub\Surface_Roughness"
merged_df = pd.read_csv(f"{base_dir}/data/processed/cleaned_data.csv")





merged_df = merged_df.drop(columns=['Fz','Fy','Fx'])


# Define the target variable
target_column = 'Surface_Roughness_Ra'
y = merged_df[target_column]



# Drop the target column to get the feature matrix
X = merged_df.drop(columns=[target_column]).copy()

print(f"Target variable '{target_column}' defined. Shape: {y.shape}")
print(f"Initial features (X) defined. Shape: {X.shape}")
print("\nFirst 5 rows of X:")
print(X.head())








print("\nScaling numerical features using StandardScaler...")

# Initialize StandardScaler
scaler = StandardScaler()

# Fit the scaler to X and transform X
X_scaled = scaler.fit_transform(X)

# Convert the scaled array back to a DataFrame, preserving column names
X_scaled_df = pd.DataFrame(X_scaled, columns=X.columns, index=X.index)


print(X_scaled_df.head())


# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)








# Define the models to be trained
models = {
    'RandomForestRegressor': RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1),
    'XGBoostRegressor': XGBRegressor(objective='reg:squarederror', n_estimators=100, random_state=42, n_jobs=-1),
    'KKNeighborsRegressor' : KNeighborsRegressor(n_neighbors=5),

}

for name, model in models.items():
    print(f"\n--- Training and Evaluating {name} ---")



    print(f"Training {name} model...")
    model.fit(X_train, y_train)
    print(f"{name} training complete.")

    # Make predictions
    y_pred = model.predict(X_test)

    # Calculate evaluation metrics
    mae = mean_absolute_error(y_test, y_pred)
    mse = mean_squared_error(y_test, y_pred)
    rmse = np.sqrt(mse)
    mape = mean_absolute_percentage_error(y_test, y_pred)
    r2 = r2_score(y_test, y_pred)

    print(f"  Mean Absolute Error (MAE): {mae:.4f}")
    print(f"  Mean Squared Error (MSE): {mse:.4f}")
    print(f"  Root Mean Squared Error (RMSE): {rmse:.4f}")
    print(f"    Mean Absolute Percentage Error (MAPE): {mape:.4f}")
    print(f"  R-squared (R2): {r2:.4f}")



models = {
    'RandomForestRegressor': {
        'model': RandomForestRegressor(random_state=42, n_jobs=-1),
        'param_grid': {
            'n_estimators': [50, 100, 200, 300, 400, 500],
            'max_depth': [None, 10, 20],
            'min_samples_split': [2, 5, 10, 15],
            'min_samples_split': [2, 5],
        }
    },
    'XGBoostRegressor': {
        'model': XGBRegressor(objective='reg:squarederror', random_state=42, n_jobs=-1),
        'param_grid': {
            'n_estimators': [50, 100, 200],
            'learning_rate': [0.01, 0.1, 0.2],
            'max_depth': [3, 5, 7, 10, 15],
            'subsample': [0.6,0.7, 1.0],
            'colsample_bytree': [0.6, 0.7, 1.0]
        }
    },
    'KNeighborsRegressor': {
        'model': KNeighborsRegressor(),
        'param_grid': {
            'n_neighbors': list(range(1, 21)),
            'weights': ['uniform', 'distance'],
            'p': [1, 2, 3], 
        }
    },
}

# Directory to save the models
model_save_dir = f"{base_dir}/trained_models/"

os.makedirs(model_save_dir, exist_ok=True)

for name, model_info in models.items():
    print(f"\n--- Training and Evaluating {name} with Grid Search ---")

    model = model_info['model']
    param_grid = model_info['param_grid']

    print(f"Performing Grid Search for {name}...")
    grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, 
                               scoring='neg_mean_squared_error', n_jobs=-1, verbose=1)
    grid_search.fit(X_train, y_train)

    best_model = grid_search.best_estimator_
    print(f"{name} Grid Search complete. Best parameters: {grid_search.best_params_}")
    print(f"Training {name} model with best parameters...")
    print(f"{name} training complete (via Grid Search).")

    # Make predictions with the best model
    y_pred = best_model.predict(X_test)

    # Calculate evaluation metrics
    # Mean Absolute Error
    mae = mean_absolute_error(y_test, y_pred)
    # Mean Squared Error
    mse = mean_squared_error(y_test, y_pred)
    # Root Mean Squared Error
    rmse = np.sqrt(mse)
    # Mean Absolute Percentage Error
    mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100 
    # Coefficient of Determination
    r2 = r2_score(y_test, y_pred)

    
    print(f"  Mean Absolute Error (MAE): {mae:.4f}")
    print(f"  Mean Squared Error (MSE): {mse:.4f}")
    print(f"  Root Mean Squared Error (RMSE): {rmse:.4f}")
    print(f"  Mean Absolute Percentage Error (MAPE): {mape:.4f}%")  
    print(f"  R-squared (R2): {r2:.4f}")
    if hasattr(best_model, 'feature_importances_'):
        importances = best_model.feature_importances_
        feature_names = X_train.columns if hasattr(X_train, 'columns') else [f'Feature {i}' for i in range(len(importances))]
        sorted_idx = np.argsort(importances)[::-1]

        plt.figure(figsize=(10, 6))
        sns.barplot(x=importances[sorted_idx], y=[feature_names[i] for i in sorted_idx], palette='viridis', hue=[feature_names[i] for i in sorted_idx])
        plt.title(f"{name} - Feature Importances")
        plt.xlabel("Importance Score")
        plt.ylabel("Features")
        plt.tight_layout()
        plt.show()



for name, model_info in models.items():

    best_model = grid_search.best_estimator_

    # Save the best model
    model_filename = os.path.join(model_save_dir, f"{name.lower()}_best_model.pkl")
    joblib.dump(best_model, model_filename)
    print(f"Best {name} model saved to directory")

print("\nAll models trained saved.")





Image(filename='ModelPredGraph.png', width=600)



    for name, model in models.items():
        lims = [min(y_test.min(), y_pred.min()), max(y_test.max(), y_pred.max())]
    
        plt.figure(figsize=(6, 6))
        plt.scatter(y_test, y_pred, alpha=0.5)
        plt.plot(lims, lims, 'r--', lw=2)
        plt.xlim(lims); plt.ylim(lims)
        plt.gca().set_aspect('equal', adjustable='box')
        plt.xlabel("Actual")
        plt.ylabel("Predicted")
        plt.title(f"Predicted vs Actual: {name}")
        plt.tight_layout()
        plt.show()



Image(filename='residuals.png', width=500)


residuals = y_test - y_pred
plt.figure(figsize=(6, 4))
plt.scatter(y_pred, residuals, alpha=0.5)
plt.axhline(0, color='r', linestyle='--')
plt.xlabel("Predicted")
plt.ylabel("Residual")
plt.title(f"Residual Plot: {name}")
plt.tight_layout()
plt.show()







X_train = X_train.drop(columns=['F'])
X_test = X_test.drop(columns=['F'])

# Define the models to be trained
models = {
    'RandomForestRegressor': RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1),
    'XGBoostRegressor': XGBRegressor(objective='reg:squarederror', n_estimators=100, random_state=42, n_jobs=-1),
    'KKNeighborsRegressor' : KNeighborsRegressor(n_neighbors=5),

}

for name, model in models.items():
    print(f"\n--- Training and Evaluating {name} ---")



    print(f"Training {name} model...")
    model.fit(X_train, y_train)
    print(f"{name} training complete.")

    # Make predictions
    y_pred = model.predict(X_test)

    # Calculate evaluation metrics
    mae = mean_absolute_error(y_test, y_pred)
    mse = mean_squared_error(y_test, y_pred)
    rmse = np.sqrt(mse)
    mape = mean_absolute_percentage_error(y_test, y_pred)
    r2 = r2_score(y_test, y_pred)

    print(f"  Mean Absolute Error (MAE): {mae:.4f}")
    print(f"  Mean Squared Error (MSE): {mse:.4f}")
    print(f"  Root Mean Squared Error (RMSE): {rmse:.4f}")
    print(f"    Mean Absolute Percentage Error (MAPE): {mape:.4f}")
    print(f"  R-squared (R2): {r2:.4f}")





